{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420e6ef1-a320-4733-855f-77b65293d55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Demand prediction problem\n",
    "class DemandPrediction:\n",
    "    N_DEMAND_INDICATORS = 13;\n",
    "    # Parameters consist of a bias (intercept) for the sum and one weight for\n",
    "    # each demand indicator.\n",
    "    N_PARAMETERS = N_DEMAND_INDICATORS + 1;\n",
    "\n",
    "    # Construct a Demand prediction problem instance.\n",
    "    # The parameter \"dataset_name\" specifies which dataset to use. Valid values\n",
    "    # are \"train\" or \"test\".\n",
    "    def __init__(self,dataset_name):\n",
    "      #Load the specified dataset\n",
    "      if(dataset_name == \"train\"):\n",
    "        self.__X, self.__y = DemandPrediction.__load_dataset(\"data/train.csv\");\n",
    "      elif(dataset_name == \"test\"):\n",
    "        self.__X, self.__y = DemandPrediction.__load_dataset(\"data/test.csv\");\n",
    "      else:\n",
    "        raise Exception(\"Only permitted arguments for \" +\n",
    "          \"DemandPrediction::__init__ are train and test.\")\n",
    "\n",
    "    # Rectangular bounds on the search space.\n",
    "    # Returns a 2D array b such that b[i][0] is the minimum permissible value\n",
    "    # of the ith solution component and b[i][1] is the maximum.\n",
    "    def bounds():\n",
    "        return [[-100,100] for i in range(DemandPrediction.N_PARAMETERS)]\n",
    "\n",
    "    # Check whether the function parameters (weights) lie within the\n",
    "    # problem's feasible region.\n",
    "    # There should be the correct number of weights for the predictor function.\n",
    "    # Each weight should lie within the range specified by the bounds.\n",
    "    def is_valid(self, parameters):\n",
    "        if(len(parameters) != DemandPrediction.N_PARAMETERS):\n",
    "          return False\n",
    "        #All weights lie within the bounds.\n",
    "        b = DemandPrediction.bounds();\n",
    "        for i in range(len(b)):\n",
    "          if(parameters[i] < b[i][0] or parameters[i] > b[i][1] ):\n",
    "            return False\n",
    "        return True;\n",
    "\n",
    "    # Evaluate a set of parameters on the dataset used by the class instance\n",
    "    # (train/test).\n",
    "    # @param parameters An containing the bias and weights to be used to\n",
    "    #   predict demand.\n",
    "    # @return The mean absolute error of the predictions on the selected\n",
    "    # dataset.\n",
    "    def evaluate(self, parameters):\n",
    "        abs_error = 0.0;\n",
    "        for (x, y) in zip(self.__X,self.__y):\n",
    "            #print(list(self.__X.values))\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            #print('--')\n",
    "            y_pred = DemandPrediction.__predict(x,parameters);\n",
    "            abs_error += abs(y-y_pred);\n",
    "        abs_error /= len(self.__X);\n",
    "        return abs_error;\n",
    "\n",
    "    def __load_dataset(filename):\n",
    "        if \"train.csv\" in filename:\n",
    "            df = pd.read_csv(filename)\n",
    "            df = df.iloc[:, 1:]\n",
    "        else:\n",
    "            df = pd.read_csv(filename,header=None)\n",
    "            # print(df.head())\n",
    "        y = df.iloc[:,0].values\n",
    "        X = df.iloc[:,1:].values\n",
    "        return X, y\n",
    "\n",
    "    # Predicts demand based on a weighted sum of demand indicators. You may\n",
    "    # replace this with something more complex, but will likely have to change\n",
    "    # the form of the parameters array as well.\n",
    "    def __predict(demand_indicators, parameters):\n",
    "        prediction = parameters[0];\n",
    "\n",
    "        for i in range(1, len(demand_indicators)):\n",
    "            prediction += demand_indicators[i] * parameters[i];\n",
    "\n",
    "        return prediction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626dff73-a0ad-4e5b-817b-c99a20229840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from DemandPrediction_v2 import DemandPrediction\n",
    "\n",
    "# Define cost function\n",
    "def cost_function(x):\n",
    "    training_problem = DemandPrediction(\"train\")\n",
    "    error = training_problem.evaluate(x)\n",
    "    return error\n",
    "\n",
    "def pso(cost_function, bounds, n_particles, n_iterations, c1, c2, w, verbose = True):\n",
    "    dimensions = len(bounds)\n",
    "    \n",
    "    # Initialize particle positions and velocities\n",
    "    positions = np.array([np.random.uniform(bounds[:, 0], bounds[:, 1], dimensions) for _ in range(n_particles)])\n",
    "    velocities = np.array([np.random.uniform(-1, 1, dimensions) for _ in range(n_particles)])\n",
    "    \n",
    "    # Initialize personal best and global best\n",
    "    personal_best_positions = np.copy(positions)\n",
    "    personal_best_costs = np.array([cost_function(p) for p in personal_best_positions])\n",
    "    global_best_position = personal_best_positions[np.argmin(personal_best_costs)]\n",
    "    global_best_cost = np.min(personal_best_costs)\n",
    "\n",
    "    error_list = []\n",
    "    # PSO main loop\n",
    "    for t in range(n_iterations):\n",
    "        for i in range(n_particles):\n",
    "            # Update particle velocity\n",
    "            r1, r2 = np.random.rand(2)\n",
    "            velocities[i] = w * velocities[i] + c1 * r1 * (personal_best_positions[i] - positions[i]) + c2 * r2 * (global_best_position - positions[i])\n",
    "\n",
    "            # Update particle position\n",
    "            positions[i] += velocities[i]\n",
    "\n",
    "            # Update personal best\n",
    "            current_cost = cost_function(positions[i])\n",
    "            if current_cost < personal_best_costs[i]:\n",
    "                personal_best_positions[i] = positions[i]\n",
    "                personal_best_costs[i] = current_cost\n",
    "\n",
    "                # Update global best\n",
    "                if current_cost < global_best_cost:\n",
    "                    global_best_position = positions[i]\n",
    "                    global_best_cost = current_cost\n",
    "\n",
    "        # Optional: print progress\n",
    "        if verbose:\n",
    "            print(\"Iteration {}/{}, Global Best Cost: {}\".format(t + 1, n_iterations, global_best_cost))\n",
    "        error_list.append(global_best_cost)\n",
    "\n",
    "    return global_best_cost, global_best_position, error_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4003f7-fa92-4470-9f0e-d4b029391076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from DemandPrediction_v2 import DemandPrediction\n",
    "\n",
    "def cost_function(x):\n",
    "    training_problem = DemandPrediction(\"train\")\n",
    "    error = training_problem.evaluate(x)\n",
    "    return error\n",
    "\n",
    "def initialize_population(pop_size, bounds):\n",
    "    dimensions = len(bounds)\n",
    "    return np.array([np.random.uniform(bounds[:, 0], bounds[:, 1], dimensions) for _ in range(pop_size)])\n",
    "\n",
    "def selection(population, fitness, num_parents):\n",
    "    parents = np.empty((num_parents, population.shape[1]))\n",
    "    for i in range(num_parents):\n",
    "        min_index = np.argmin(fitness)\n",
    "        parents[i] = population[min_index]\n",
    "        fitness[min_index] = float('inf')\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "    crossover_point = np.uint32(offspring_size[1] / 2)\n",
    "    for k in range(offspring_size[0]):\n",
    "        parent1_index = k % parents.shape[0]\n",
    "        parent2_index = (k + 1) % parents.shape[0]\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_index, 0:crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_index, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring, bounds, mutation_rate):\n",
    "    for i in range(offspring.shape[0]):\n",
    "        for j in range(offspring.shape[1]):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                random_value = np.random.uniform(bounds[j, 0], bounds[j, 1])\n",
    "                offspring[i, j] = random_value\n",
    "    return offspring\n",
    "\n",
    "def ga(cost_function, bounds, pop_size, num_generations, mutation_rate, verbose = True):\n",
    "    # GA parameters\n",
    "    # pop_size = 100\n",
    "    # num_generations = 1000\n",
    "    num_parents = int(pop_size / 2)\n",
    "    # mutation_rate = 0.5\n",
    "\n",
    "    # bounds = np.array(DemandPrediction.bounds())\n",
    "\n",
    "    # Initialize population\n",
    "    population = initialize_population(pop_size, bounds)\n",
    "\n",
    "    error_list = []\n",
    "    # Run GA optimization\n",
    "    for generation in range(num_generations):\n",
    "        fitness = np.array([cost_function(individual) for individual in population])\n",
    "        parents = selection(population, fitness.copy(), num_parents)\n",
    "        offspring = crossover(parents, offspring_size=(pop_size - num_parents, bounds.shape[0]))\n",
    "        offspring = mutation(offspring, bounds, mutation_rate)\n",
    "        population[0:parents.shape[0]] = parents\n",
    "        population[parents.shape[0]:] = offspring\n",
    "\n",
    "        # Optional: print progress\n",
    "        best_individual = population[np.argmin(fitness)]\n",
    "        best_fitness = np.min(fitness)\n",
    "        if verbose:\n",
    "            print(\"Generation {}/{}, Best Fitness: {}\".format(generation + 1, num_generations, best_fitness))\n",
    "        error_list.append(best_fitness)\n",
    "\n",
    "    # Get the best solution\n",
    "    best_solution = population[np.argmin(fitness)]\n",
    "    best_cost = np.min(fitness)\n",
    "\n",
    "    print(\"Best training error after {} generations: {}\".format(num_generations, best_cost))\n",
    "\n",
    "    # Check the MAE of the best solution on the test problem\n",
    "    test_problem = DemandPrediction(\"test\")\n",
    "    test_error = test_problem.evaluate(best_solution)\n",
    "    print(\"Test error of best solution found while training: {}\".format(test_error))\n",
    "    return best_solution, best_cost, error_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47e29dcc-b89c-40e2-a068-f45dd82f3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "#from DemandPrediction_v2 import DemandPrediction\n",
    "from scipy.stats import f_oneway\n",
    "#from Main_PSO_v4 import pso\n",
    "#from Main_Genetic import ga\n",
    "\n",
    "bounds = np.array(DemandPrediction.bounds())\n",
    "\n",
    "# Define cost function\n",
    "def cost_function(x):\n",
    "    training_problem = DemandPrediction(\"train\")\n",
    "    error = training_problem.evaluate(x)\n",
    "    return error\n",
    "\n",
    "def run_pso(params):\n",
    "    cost_function, bounds, n_particles, n_iterations, c1, c2, w = params\n",
    "    best_cost, best_position ,err = pso(cost_function, bounds, n_particles, n_iterations, c1, c2, w, verbose=False)\n",
    "    test_problem = DemandPrediction(\"test\")\n",
    "    test_error = test_problem.evaluate(best_position)\n",
    "    return test_error\n",
    "\n",
    "def run_genetic(params):\n",
    "    cost_function, bounds, pop_size, num_generations, mutation_rate = params\n",
    "    best_solution, best_cost , err = ga(cost_function, bounds, pop_size, num_generations, mutation_rate, verbose=False)\n",
    "    test_problem = DemandPrediction(\"test\")\n",
    "    test_error = test_problem.evaluate(best_solution)\n",
    "    return test_error\n",
    "\n",
    "def compare_models(num_runs, pso_params, genetic_params):\n",
    "    #pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    #pso_results = pool.map(run_pso, [pso_params] * num_runs)\n",
    "    #genetic_results = pool.map(run_genetic, [genetic_params] * num_runs)\n",
    "    genetic_results=[]    \n",
    "    pso_results=[]\n",
    "    for param in range(num_runs):\n",
    "        pso_results.append(run_pso(pso_params))\n",
    "    for param in range(num_runs):\n",
    "        genetic_results.append(run_genetic(genetic_params))\n",
    "    \n",
    "    #pool.close()\n",
    "    #pool.join()\n",
    "\n",
    "    f_stat, p_value = f_oneway(pso_results, genetic_results)\n",
    "    \n",
    "    print(\"PSO Results: \", pso_results)\n",
    "    print(\"Genetic Algorithm Results: \", genetic_results)\n",
    "    print(\"ANOVA F Statistic: \", f_stat)\n",
    "    print(\"ANOVA P Value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de618b43-419f-448a-a618-f6fe31b616e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training error after 2 generations: 386.1773025277074\n",
      "Test error of best solution found while training: 6461.819628666617\n",
      "Best training error after 2 generations: 677.3095807441819\n",
      "Test error of best solution found while training: 3445.7168319644593\n",
      "Best training error after 2 generations: 685.6034412532098\n",
      "Test error of best solution found while training: 8228.152009170208\n",
      "Best training error after 2 generations: 858.4638311661172\n",
      "Test error of best solution found while training: 20748.259760565634\n",
      "Best training error after 2 generations: 800.3790944965068\n",
      "Test error of best solution found while training: 2936.6133702349516\n",
      "PSO Results:  [1212.486042358312, 1402.334719363462, 5369.377301168657, 556.9886884262561, 4004.4320489236256]\n",
      "Genetic Algorithm Results:  [6461.819628666617, 3445.7168319644593, 8228.152009170208, 20748.259760565634, 2936.6133702349516]\n",
      "ANOVA F Statistic:  3.009910903408915\n",
      "ANOVA P Value:  0.12097650692546556\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #mp.set_start_method('spawn')\n",
    "    \n",
    "    #num_runs = 30\n",
    "    num_runs = 5\n",
    "    #pso_params = (cost_function, bounds, 100, 1000, 0.7, 0.7, 0.7)\n",
    "    #genetic_params = (cost_function, bounds, 150, 1500, 0.2)\n",
    "    \n",
    "    pso_params = (cost_function, bounds, 100, 2, 0.7, 0.7, 0.7)\n",
    "    genetic_params = (cost_function, bounds, 150, 2, 0.2)\n",
    "\n",
    "    compare_models(num_runs, pso_params, genetic_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
